{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자연어 처리 입문_2.텍스트 전처리.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOetvEcuoYMM0+kxdF6ufSl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pumkinni/book_study/blob/master/%EC%9E%90%EC%97%B0%EC%96%B4_%EC%B2%98%EB%A6%AC_%EC%9E%85%EB%AC%B8_2_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%A0%84%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1)토큰화"
      ],
      "metadata": {
        "id": "ADzj-8Vvkif-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "3r6zaos9loeY",
        "outputId": "366b1290-1f50-4d3c-fcf0-3c9d8efa48d4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "JVYKnmMrlPsf",
        "outputId": "7678b537-ed70-4467-feb6-7935a572e369"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "gensim.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "_tb39JZQlzLc",
        "outputId": "d7a9546b-95a1-4d92-c8ab-b8e16e6c8759"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sklearn.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "hLnVeA9dmAU8",
        "outputId": "ec298b71-4540-43ac-c4dc-21684a6131a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.0.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "vuDSSnxVmKLv",
        "outputId": "dfe85381-a9f5-4415-b6a9-9c46f7f1e03c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import konlpy\n",
        "konlpy.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "tMH72lFdmKIv",
        "outputId": "26b12965-b095-4cad-a0a5-22e7d86ac3b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.6.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ww4xeQN4j_c8"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "word_tokenize\n",
        "\n",
        "Don't -> Do , n't 로 분리\n",
        "\n",
        "Jone's -> Jone , 's 로 분리"
      ],
      "metadata": {
        "id": "Ipmt9s2RpfsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "문장 = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
        "print('word_toknize', word_tokenize(문장))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acs1iq7Wksy1",
        "outputId": "28b01ef3-b9e9-49de-9309-e3d04272f861"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_toknize ['Do', \"n't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr.', 'Jone', \"'s\", 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordPunctTokenizer()\n",
        "\n",
        "구두점을 별도로 분류\n",
        "Don't -> Don , ' , t 로 분류\n",
        "\n",
        "Jone's -> Jone , ' , s 로 분류"
      ],
      "metadata": {
        "id": "qM-6v3Iip4hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('WordPunctTokenizer' , WordPunctTokenizer().tokenize(문장))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "If090ms_o0m6",
        "outputId": "10afb72f-43e9-4ca9-d043-43c239a3ec8c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WordPunctTokenizer ['Don', \"'\", 't', 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', ',', 'Mr', '.', 'Jone', \"'\", 's', 'Orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "text_to_word_sequence(문장)\n",
        "\n",
        "모든 알파벳을 소문자로 바꾸면서 마침표나 컴마, 느낌표 등의 구두점을 제거하지만 don't나 jone's와 같은 경우는 '를 보존\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "szQqlIm6qVvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('text_to_word_sequence', text_to_word_sequence(문장))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SIZl6v3pabC",
        "outputId": "2165cf91-36c2-4c49-b9e6-e740c9b7b294"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text_to_word_sequence [\"don't\", 'be', 'fooled', 'by', 'the', 'dark', 'sounding', 'name', 'mr', \"jone's\", 'orphanage', 'is', 'as', 'cheery', 'as', 'cheery', 'goes', 'for', 'a', 'pastry', 'shop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TreebankWordTokenizer()\n",
        "\n",
        "1. 하이푼으로 구성된 단어는 하나로 유지한다.\n",
        "ex) home-based 하나의 토큰으로 취급\n",
        "\n",
        "2. doesn't와 같이 아포스트로피로 '접어'가 함께하는 단어는 분리해준다.\n",
        "ex) doesn't -> does , n't\n"
      ],
      "metadata": {
        "id": "zw_Erg0Ms777"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "문장 = \"Starting a home-based restaurant may be an ideal. it doesn't have a food chain or restaurant of their own.\"\n",
        "print('트리뱅크 워드토크나이저 : ', tokenizer.tokenize(문장))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4d_ug6gpa77",
        "outputId": "d5588e20-fca9-44de-ed44-6c037b01d204"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "트리뱅크 워드토크나이저 :  ['Starting', 'a', 'home-based', 'restaurant', 'may', 'be', 'an', 'ideal.', 'it', 'does', \"n't\", 'have', 'a', 'food', 'chain', 'or', 'restaurant', 'of', 'their', 'own', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 문장의 토큰화(Sentence Tokenization)\n",
        "코퍼스 내에서 문장 단위로 구분하는 작업"
      ],
      "metadata": {
        "id": "1lcGMO-Rugeo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sent_tokenize\n",
        "\n",
        "영어 문장 토큰화\n",
        "\n",
        "단순히 마침표를 기준으로 토큰화 X"
      ],
      "metadata": {
        "id": "KKS5QbTCvIJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "문장 = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "\n",
        "print('영어 문장 토큰화' , sent_tokenize(문장))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiGV__DzuTDE",
        "outputId": "c16c0b22-8957-49fc-8dd9-20560bce6436"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 문장 토큰화 ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "문장 = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
        "\n",
        "print('영어 문장 토큰화' , sent_tokenize(문장))\n",
        "\n",
        "문장2 = \"I am actively looking for Ph.D. students. and you are a Ph.D student.\"\n",
        "print('중간중간 마침표가 나오는 문장 토큰화' , sent_tokenize(문장2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyOcJ2GBvnie",
        "outputId": "3e8431ab-39e0-4d45-f1de-ce3a66496641"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "영어 문장 토큰화 ['His barber kept his word.', 'But keeping such a huge secret to himself was driving him crazy.', 'Finally, the barber went up a mountain and almost to the edge of a cliff.', 'He dug a hole in the midst of some reeds.', 'He looked about, to make sure no one was near.']\n",
            "중간중간 마침표가 나오는 문장 토큰화 ['I am actively looking for Ph.D. students.', 'and you are a Ph.D student.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "한국어 문장 토큰화 kss"
      ],
      "metadata": {
        "id": "Et5fbdmKwWKY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "문장 = '딥러닝이란 무엇인가? 이제 조금 알아가는 중이에요. 여전히 어렵지만 재미가 있네요. 다들 너무 대단한걸요?'\n",
        "\n",
        "print('한국어 문장 토큰화', kss.split_sentences(문장))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7FaQoEbwNch",
        "outputId": "4b620c13-b278-4518-dfcf-6197a2197dd7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Korean Sentence Splitter]: Initializing Pynori...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "한국어 문장 토큰화 ['딥러닝이란 무엇인가?', '이제 조금 알아가는 중이에요.', '여전히 어렵지만 재미가 있네요.', '다들 너무 대단한걸요?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "품사 태깅\n",
        "\n",
        "PRP는 인칭 대명사, VBP는 동사, RB는 부사, VBG는 현재부사, IN은 전치사, NNP는 고유 명사, NNS는 복수형 명사, CC는 접속사, DT는 관사를 의미"
      ],
      "metadata": {
        "id": "p6U8QT6p1alR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag #품사 태깅\n",
        "\n",
        "text = \"I am actively looking for Ph.D. students. and you are a Ph.D. student.\"\n",
        "tokenized_sentence = word_tokenize(text)\n",
        "\n",
        "print('단어 토큰화 :',tokenized_sentence)\n",
        "print('품사 태깅 :',pos_tag(tokenized_sentence))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBeuQB1lwbXz",
        "outputId": "b966ccbc-525e-43c9-da47-be421a16591b"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 토큰화 : ['I', 'am', 'actively', 'looking', 'for', 'Ph.D.', 'students', '.', 'and', 'you', 'are', 'a', 'Ph.D.', 'student', '.']\n",
            "품사 태깅 : [('I', 'PRP'), ('am', 'VBP'), ('actively', 'RB'), ('looking', 'VBG'), ('for', 'IN'), ('Ph.D.', 'NNP'), ('students', 'NNS'), ('.', '.'), ('and', 'CC'), ('you', 'PRP'), ('are', 'VBP'), ('a', 'DT'), ('Ph.D.', 'NNP'), ('student', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "형태소 토큰화-okt, kkma (속도를 중시한다면 macap)\n",
        "\n",
        "1) morphs : 형태소 추출\n",
        "\n",
        "2) pos : 품사 태깅(Part-of-speech tagging)\n",
        "\n",
        "3) nouns : 명사 추출"
      ],
      "metadata": {
        "id": "6CKeBsoS2bA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "okt = Okt()\n",
        "kkma = Kkma()\n",
        "\n",
        "print('OKT 형태소 분석 :',okt.morphs(\"오늘도 열심히 코딩했다. 자만하지마\"))\n",
        "print('OKT 품사 태깅 :',okt.pos(\"오늘도 열심히 코딩했다. 자만하지마\"))\n",
        "print('OKT 명사 추출 :',okt.nouns(\"오늘도 열심히 코딩했다. 자만하지마\")) \n",
        "print('')\n",
        "\n",
        "print('꼬꼬마 형태소 분석 :',kkma.morphs(\"오늘도 열심히 코딩했다. 자만하지마\"))\n",
        "print('꼬꼬마 품사 태깅 :',kkma.pos(\"오늘도 열심히 코딩했다. 자만하지마\"))\n",
        "print('꼬꼬마 명사 추출 :',kkma.nouns(\"오늘도 열심히 코딩했다. 자만하지마\"))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXFcBGJe1ulp",
        "outputId": "e19465a4-74a6-4aea-9392-7ad8b300eeca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OKT 형태소 분석 : ['오늘', '도', '열심히', '코딩', '했다', '.', '자만하지마']\n",
            "OKT 품사 태깅 : [('오늘', 'Noun'), ('도', 'Josa'), ('열심히', 'Adverb'), ('코딩', 'Noun'), ('했다', 'Verb'), ('.', 'Punctuation'), ('자만하지마', 'Adjective')]\n",
            "OKT 명사 추출 : ['오늘', '코딩']\n",
            "\n",
            "꼬꼬마 형태소 분석 : ['오늘', '도', '열심히', '코딩', '하', '었', '다', '.', '자만', '하', '지', '말']\n",
            "꼬꼬마 품사 태깅 : [('오늘', 'NNG'), ('도', 'JX'), ('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF'), ('자만', 'NNG'), ('하', 'XSV'), ('지', 'ECD'), ('말', 'VXV')]\n",
            "꼬꼬마 명사 추출 : ['오늘', '코딩', '자만']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "›print('꼬꼬마 형태소 분석 :',kkma.morphs(\"오늘도 열심히 코딩했다. 자만하지마\"))\n",
        "print('꼬꼬마 품사 태깅 :',kkma.pos(\"오늘도 열심히 코딩했다. 자만하지마\"))\n",
        "print('꼬꼬마 명사 추출 :',kkma.nouns(\"오늘도 열심히 코딩했다. 자만하지마\"))  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pDG1c092jU1",
        "outputId": "8588f675-4a77-4d14-ee59-9fba8173d1d5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "꼬꼬마 형태소 분석 : ['오늘', '도', '열심히', '코딩', '하', '었', '다', '.', '자만', '하', '지', '말']\n",
            "꼬꼬마 품사 태깅 : [('오늘', 'NNG'), ('도', 'JX'), ('열심히', 'MAG'), ('코딩', 'NNG'), ('하', 'XSV'), ('었', 'EPT'), ('다', 'EFN'), ('.', 'SF'), ('자만', 'NNG'), ('하', 'XSV'), ('지', 'ECD'), ('말', 'VXV')]\n",
            "꼬꼬마 명사 추출 : ['오늘', '코딩', '자만']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z55hf-C5ALlu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}